import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import streamlit as st
import pickle
import scipy as sp
import os, tempfile
import numpy as np
import matplotlib.animation as animation
from matplotlib.animation import PillowWriter

from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# ====== å®šæ•° ======
LABEL_NAMES = {0: "Stop", 1: "Distracted\nWalking", 2: "Not Distracted\nWalking"}
FEATURE_COLS = ["ax", "ay", "az", "wx", "wy", "wz"]
SAMPLING_RATE = 100

# ====== ç‰¹å¾´é‡æŠ½å‡º ======
def extract_features_from_segment(segment: pd.DataFrame) -> dict:
    for c in FEATURE_COLS:
        if c not in segment.columns:
            raise ValueError(f"åˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {c}")

    feats = {}
    for col in FEATURE_COLS:
        s = segment[col]
        feats[f"{col}_mean"]   = s.mean() # å¹³å‡å€¤
        feats[f"{col}_std"]    = s.std() # åå·®
        feats[f"{col}_min"]    = s.min() # æœ€å°å€¤
        feats[f"{col}_max"]    = s.max() # æœ€å¤§å€¤
        feats[f"{col}_median"] = s.median() # ä¸­å¤®å€¤
        feats[f"{col}_range"]  = s.max() - s.min() # ç¯„å›²
        feats[f"{col}_q1"] = s.quantile(0.25) # ç¬¬ä¸€å››åˆ†ä½æ•°
        feats[f"{col}_q3"] = s.quantile(0.75) # ç¬¬ä¸‰å››åˆ†ä½æ•°
        feats[f'{col}_skew'] = s.skew() # æ­ªåº¦
        feats[f'{col}_kurt'] = s.kurt() # å°–åº¦
        feats[f'{col}_iqr'] = sp.stats.iqr(s) # å››åˆ†ä½ç¯„å›²

    if "class" in segment.columns and not segment["class"].empty:
        feats["class"] = segment["class"].mode().iloc[0]

    return feats


def segment_and_extract(df: pd.DataFrame, window_size: int, stride: int) -> pd.DataFrame:
    rows, n = [], len(df)
    for start in range(0, max(n - window_size + 1, 0), stride):
        seg = df.iloc[start : start + window_size]
        rows.append(extract_features_from_segment(seg))

    if not rows:
        raise ValueError("ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒä½œã‚Œã¾ã›ã‚“ã€‚window/stride ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")

    return pd.DataFrame(rows)


# ====== å­¦ç¿’ãƒ»è©•ä¾¡ ======
def train_and_evaluate(feature_df: pd.DataFrame, tree: int, max_depth: int):
    if "class" not in feature_df.columns:
        raise ValueError("ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã« 'class' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    X = feature_df.drop(columns=["class"])
    y = feature_df["class"]
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.8, stratify=y, random_state=42)

    rf = RandomForestClassifier(n_estimators=tree, max_depth=max_depth, random_state=42)
    rf.fit(Xtr, ytr)

    yhat = rf.predict(Xte)
    acc = metrics.accuracy_score(yte, yhat)

    classes_sorted = sorted(pd.unique(y))
    disp_labels = [LABEL_NAMES.get(c, str(c)) for c in classes_sorted]
    cm = confusion_matrix(yte, yhat, labels=classes_sorted)

    fig, ax = plt.subplots(figsize=(6, 5), dpi=150)
    ConfusionMatrixDisplay(cm, display_labels=disp_labels).plot(ax=ax, colorbar=False)
    ax.set_title("Confusion Matrix - RandomForest")
    fig.tight_layout()

    return rf, acc, fig

def predict_segment(model, df_segment: pd.DataFrame):
    feats = extract_features_from_segment(df_segment)
    X = pd.DataFrame([feats]).drop(columns=[c for c in ["class"] if c in feats], errors="ignore")
    pred = model.predict(X)[0]
    return LABEL_NAMES.get(pred, str(pred))

def make_prediction_gif(pred_df: pd.DataFrame, model, window_size: int, stride: int) -> bytes:
    # å¿…é ˆåˆ—
    need = {"time", "ax"}
    if not need.issubset(set(pred_df.columns)):
        raise ValueError(f"äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«å¿…è¦ãªåˆ—ãŒè¶³ã‚Šã¾ã›ã‚“: {sorted(list(need - set(pred_df.columns)))}")

    t = pred_df["time"].to_numpy()
    y = pred_df["ax"].to_numpy()
    total = len(y)

    fig, ax = plt.subplots(figsize=(10, 5), dpi=130)
    ax.plot(t, y, alpha=0.5, label="Full ax")
    (dyn_line,) = ax.plot([], [], lw=2, label="Window")
    ax.legend(loc="upper right")
    ax.set_xlabel("Time")
    ax.set_ylabel("ax")
    ax.set_ylim(np.min(y) - 0.5, np.max(y) + 0.5)
    title = ax.set_title("result: (computing...)")

    def update(i):
        start = i * stride
        end = min(start + window_size, total)
        if end - start < window_size:
            start = max(0, total - window_size)
            end = total
        dyn_line.set_data(t[start:end], y[start:end])

        seg = pred_df.iloc[start:end].drop(columns=[c for c in ["time","detail"] if c in pred_df.columns], errors="ignore")
        title.set_text(f"result: {predict_segment(model, seg)}")
        return dyn_line, title

    frames = max((total - window_size) // stride + 1, 1)
    ani = animation.FuncAnimation(fig, update, frames=frames, interval=400)
    plt.close(fig)

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ã‹ã‚‰ bytes èª­ã¿å‡ºã—
    with tempfile.NamedTemporaryFile(suffix=".gif", delete=False) as tmp:
        tmp_path = tmp.name
    ani.save(tmp_path, writer=PillowWriter(fps=5))
    with open(tmp_path, "rb") as f:
        data = f.read()
    os.remove(tmp_path)
    return data

# ====== äºˆæ¸¬ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã®ãƒ©ãƒ™ãƒ«ã¨æ™‚é–“ï¼ˆé›†è¨ˆç”¨ï¼‰ ======
def predict_windows_with_time(pred_df: pd.DataFrame, model, window_size: int, stride: int) -> pd.DataFrame:
    """
    pred_data.xlsx ã‚’ window/stride ã§ã‚¹ãƒ©ã‚¤ãƒ‰ã—ã€
    å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã¨ [é–‹å§‹æ™‚åˆ», çµ‚äº†æ™‚åˆ», ç¶™ç¶šæ™‚é–“] ã‚’è¿”ã™ã€‚
    timeåˆ—ãŒæ•°å€¤(ç§’ç­‰)ãªã‚‰ãã®ã¾ã¾ã€æ—¥æ™‚ãªã‚‰å…ˆé ­ã‚’0ç§’ã¨ã—ã¦å·®åˆ†ç§’ã«æ›ç®—ã€‚
    """
    if "time" not in pred_df.columns:
        raise ValueError("äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã« 'time' åˆ—ãŒå¿…è¦ã§ã™ã€‚")

    time_col = pred_df["time"]

    # timeåˆ—ãŒæ•°å€¤ãªã‚‰ãã®ã¾ã¾ã€æ—¥æ™‚ãªã‚‰ç§’ã¸
    if np.issubdtype(time_col.dtype, np.number):
        tsec = time_col.to_numpy().astype(float)
    else:
        t_dt = pd.to_datetime(time_col, errors="coerce")
        if t_dt.isna().any():
            # å¤‰æ›ä¸å¯ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç§’æ‰±ã„ï¼ˆ1ã‚µãƒ³ãƒ—ãƒ«=1ï¼‰
            tsec = np.arange(len(time_col), dtype=float)
        else:
            t0 = t_dt.iloc[0]
            tsec = (t_dt - t0).dt.total_seconds().to_numpy()

    n = len(pred_df)
    rows = []
    idx = 0
    while True:
        start = idx * stride
        if start >= n:
            break
        end = min(start + window_size, n)
        if end - start < window_size:
            start = max(0, n - window_size)
            end = n

        seg = pred_df.iloc[start:end].drop(columns=[c for c in ["time","detail"] if c in pred_df.columns], errors="ignore")
        label = predict_segment(model, seg)

        t_start = float(tsec[start])
        t_end   = float(tsec[end - 1])
        dur     = max(0.0, t_end - t_start)

        rows.append({
            "start_time_s": t_start,
            "end_time_s":   t_end,
            "duration_s":   dur,
            "label":        label
        })

        idx += 1
        if end >= n:
            break

    return pd.DataFrame(rows)

# ====== Streamlit UI ======
st.set_page_config(page_title="train model", page_icon=":material/network_intelligence_update:")
st.title("ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒšãƒ¼ã‚¸")
if st.session_state["login"]:
    with st.sidebar:
        st.header("ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        st.write(f'ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º : {st.session_state["window_size"]}')
        st.write(f'ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ : {st.session_state["stride"]}')

        st.header("ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        st.write(f'æœ¨ã®æ•°(n_estimators) : {st.session_state["n_estimators"]}')
        st.write(f'æœ€å¤§æ·±ã•(max_depth) : {st.session_state["max_depth"]}')

    st.subheader("å­¦ç¿’ç”¨Excelï¼ˆtrain_data.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    model_file = st.file_uploader("åˆ—: time, ax, ay, az, wx, wy, wz, class, detailï¼ˆdetailã¯ä»»æ„ï¼‰", type=["xlsx"])
    st.subheader("ãƒ†ã‚¹ãƒˆç”¨Excel(test_data.xlsx) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    pred_file = st.file_uploader("åˆ—: time, ax, ay, az, wx, wy, wz", type=["xlsx"])

    # -------- å®Ÿè¡Œãƒœã‚¿ãƒ³ --------
    if st.button("å®Ÿè¡Œã™ã‚‹", disabled=not(model_file)):
        try:
            with st.spinner("ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸­..."):
                train_df = pd.read_excel(model_file)
                train_df = train_df.drop(columns=[c for c in ["time", "detail"] if c in train_df.columns], errors="ignore")
                    
                feat_df = segment_and_extract(train_df, st.session_state["window_size"], st.session_state["stride"])
                st.success(f"ç‰¹å¾´é‡: {feat_df.shape[0]} ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ / {feat_df.shape[1]} åˆ—")

                rf, acc, fig_cm = train_and_evaluate(feat_df, st.session_state["n_estimators"], st.session_state["max_depth"])
                st.metric("RandomForest accuracy", f"{acc:.4f}")
                st.pyplot(fig_cm, clear_figure=True)
                    
                # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ & GIF
                pred_df = pd.read_excel(pred_file)
                gif_bytes = make_prediction_gif(pred_df, rf, st.session_state["window_size"], st.session_state["stride"])
                st.image(gif_bytes, caption="prediction_animation.gif", use_container_width=True)
                st.download_button("GIFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=gif_bytes, file_name="prediction_animation.gif", mime="image/gif")

                # === äºˆæ¸¬ãƒ©ãƒ™ãƒ« Ã— æ™‚é–“ã®é›†è¨ˆ ===
                win_df = predict_windows_with_time(pred_df, rf, st.session_state["window_size"], st.session_state["stride"])
                if not win_df.empty:
                    # ãƒ©ãƒ™ãƒ«ã”ã¨åˆè¨ˆç§’
                    agg = (win_df
                        .groupby("label", as_index=False)["duration_s"].sum()
                        .sort_values("duration_s", ascending=False))
                    total_sec = agg["duration_s"].sum()
                    agg["ratio_%"] = (agg["duration_s"] / total_sec * 100.0) if total_sec > 0 else 0.0

                    st.subheader("äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã”ã¨ã®åˆè¨ˆæ™‚é–“")
                    st.dataframe(agg, use_container_width=True, hide_index=True)

                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆStop / Distracted / Not Distractedï¼‰
                    def fmt_hms(sec: float) -> str:
                        m, s = divmod(int(round(sec)), 60)
                        return f"{m:02d}:{s:02d}"

                    c1, c2, c3 = st.columns(3)
                    def show_metric(col, label_name, display_name):
                        v = agg.loc[agg["label"] == label_name, "duration_s"]
                        sec = float(v.iloc[0]) if not v.empty else 0.0
                        col.metric(display_name, f"{sec:.2f} s")
                        col.caption(f"â± {fmt_hms(sec)}")

                    show_metric(c1, "Stop", "Stop")
                    show_metric(c2, "Distracted\nWalking", "Distracted Walking")
                    show_metric(c3, "Not Distracted\nWalking", "Not Distracted Walking")

                    # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆé›†è¨ˆï¼‰
                    st.download_button(
                        "ãƒ©ãƒ™ãƒ«åˆ¥åˆè¨ˆæ™‚é–“ã‚’CSVã§ä¿å­˜",
                        data=agg.to_csv(index=False).encode("utf-8-sig"),
                        file_name="label_duration_summary.csv",
                        mime="text/csv",
                    )
                    # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è©³ç´°ï¼‰
                    st.download_button(
                        "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã®äºˆæ¸¬ã¨æ™‚é–“ï¼ˆè©³ç´°CSVï¼‰",
                        data=win_df.to_csv(index=False).encode("utf-8-sig"),
                        file_name="window_predictions.csv",
                        mime="text/csv",
                    )
                    # ====== å­¦ç¿’ãƒ¢ãƒ‡ãƒ« ä¿å­˜ï¼ˆæ­£å¸¸å‹•ä½œã™ã‚‹ã‚ˆã†ä¿®æ­£æ¸ˆã¿ï¼‰======
                    st.download_button(
                        "å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’pickleå½¢å¼ã§ä¿å­˜",
                        data=pickle.dumps(rf),
                        file_name="model.pkl",
                    )
                else:
                    st.info("ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒä½œã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚window/stride ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.warning("ã“ã®æ©Ÿèƒ½ã‚’ä½¿ã†ã«ã¯ãƒ›ãƒ¼ãƒ ã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„", icon="ğŸš¨")
